{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch.helpers import scan\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">There are <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">924</span> documents in the index <span style=\"color: #008000; text-decoration-color: #008000\">'technical_ind'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "There are \u001b[1;36m924\u001b[0m documents in the index \u001b[32m'technical_ind'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 924/924 [00:10<00:00, 85.24it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">There are <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">924</span> documents in the index <span style=\"color: #008000; text-decoration-color: #008000\">'objective_ind'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "There are \u001b[1;36m924\u001b[0m documents in the index \u001b[32m'objective_ind'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 924/924 [00:07<00:00, 119.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "client = Elasticsearch(\"http://localhost:9200\", request_timeout=1000)\n",
    "\n",
    "index_names = ['technical_ind', 'objective_ind']\n",
    "corpuses = {'technical_ind':{}, 'objective_ind':{}}\n",
    "for index_name in index_names:\n",
    "    ndocs = int(client.cat.count(index=index_name, format = \"json\")[0]['count'])\n",
    "    print(f\"There are {ndocs} documents in the index '{index_name}'\")\n",
    "\n",
    "\n",
    "    corpus = corpuses[index_name]    # will store _normalized_ tfidf for each document, key is internal elasticsearch id, value is dictionary of term -> tf-idf weight\n",
    "    for s in tqdm.tqdm(scan(client, index=index_name, query={\"query\" : {\"match_all\": {}}}), total=ndocs):\n",
    "        terms = []\n",
    "        freqs = []\n",
    "        dfs = []\n",
    "\n",
    "        tv = client.termvectors(index=index_name, id=s['_id'], fields=['text'], term_statistics=True, positions=False)\n",
    "        if 'text' in tv['term_vectors']:   # just in case some document has no field named 'text'\n",
    "            for t in tv['term_vectors']['text']['terms']:\n",
    "                f = tv['term_vectors']['text']['terms'][t]['term_freq']\n",
    "\n",
    "                terms.append(t)\n",
    "                freqs.append(tv['term_vectors']['text']['terms'][t]['term_freq'])\n",
    "                dfs.append(tv['term_vectors']['text']['terms'][t]['doc_freq'])\n",
    "\n",
    "        # vector computations for tf-idf; l2-normalized for further calculations..\n",
    "        tfidf = np.array(freqs) * np.log2(ndocs / np.array(dfs))\n",
    "        tfidf /= np.linalg.norm(tfidf)\n",
    "\n",
    "        # save in corpus dictionary\n",
    "        corpus[s['_source']['path']] = {t: tfidf[j] for j, t in enumerate(terms)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "\n",
    "print(corpuses['objective_ind'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports ###\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import heapq\n",
    "import tqdm\n",
    "import uuid\n",
    "from pprint import pprint\n",
    "from collections import Counter, defaultdict\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import scan\n",
    "from elasticsearch_dsl import Search, Index, analyzer, tokenizer\n",
    "from elasticsearch_dsl.query import Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(query: str) -> str:\n",
    "    res = ind.analyze(body={'analyzer':'default', 'text': query})\n",
    "    query_stemmed = ''\n",
    "    first = True\n",
    "    for r in res['tokens']:\n",
    "        if not first:\n",
    "            query_stemmed += ' ' + r['token']\n",
    "        else:\n",
    "            query_stemmed += r['token']\n",
    "            first = False\n",
    "    return query_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(d: list[tuple[str, float]]) -> float:\n",
    "    return np.sqrt(sum([freq*freq for term, freq in d]))\n",
    "\n",
    "\n",
    "def normalize(d1: list[tuple[str, float]]):\n",
    "    normm = norm(d1)\n",
    "    return [(k, v/normm) for k, v in d1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 924/924 [00:00<00:00, 2311.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch.helpers import scan\n",
    "from pprint import pprint\n",
    "from elasticsearch import Elasticsearch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "client = Elasticsearch(\"http://localhost:9200\", request_timeout=1000)\n",
    "\n",
    "r = 10  # only return r top docs\n",
    "queries = ['win prize many top dive trophy limit victory','learn skills dive improve gain experience', 'first try begin people knowledge start','level experiment journey collaborate experience']\n",
    "sims : dict[str, dict[int,float]] = {}\n",
    "\n",
    "l2query  = [np.sqrt(len(query.split())) for query in queries]  # l2 of query assuming 0-1 vector representation\n",
    "\n",
    "# get nr. of docs; just for the progress bar\n",
    "ndocs = int(client.cat.count(index='objective_ind', format = \"json\")[0]['count'])\n",
    "\n",
    "# scan through docs, compute cosine sim between query and each doc\n",
    "for s in tqdm.tqdm(scan(client, index='objective_ind', query={\"query\" : {\"match_all\": {}}}), total=ndocs):\n",
    "    \n",
    "    docid = s['_source']['path']   # use path as id\n",
    "    weights = corpuses['objective_ind'][docid]   # gets weights as a python dict of term -> weight (see remark above)\n",
    "    docid = docid.split('/')[-1].replace('.txt', '')\n",
    "    sims[docid] = {}\n",
    "    for i in range(len(queries)):\n",
    "        sims[docid][i] = 0.0\n",
    "        for w in queries[i].split():  # gets terms as a list\n",
    "            if w in weights:    # probably need to do something fancier to make sure that word is in vocabulary etc.\n",
    "                sims[docid][i] += weights[w]   # accumulates if w in current doc\n",
    "        # normalize sim\n",
    "        sims[docid][i] /= l2query[i]\n",
    "\n",
    "# now sort by cosine similarity\n",
    "#sorted_answer = sorted(sims.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "#pprint(sorted_answer[:r])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sims.keys():\n",
    "    if sims[i][2] > 0.1:\n",
    "        print(i, sims[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abil': 0.08397771618210773,\n",
       " 'be': 0.11216450959639765,\n",
       " 'been': 0.12377455366192551,\n",
       " 'best': 0.07079818365769823,\n",
       " 'blockchain': 0.12369664517208896,\n",
       " 'bring': 0.06339890890171522,\n",
       " 'clear': 0.11477064158931573,\n",
       " 'close': 0.1867315612323537,\n",
       " 'code': 0.01913849682507567,\n",
       " 'collabor': 0.11102753009373281,\n",
       " 'come': 0.0394593597615803,\n",
       " 'competit': 0.04310459432894165,\n",
       " 'confid': 0.06937303615927695,\n",
       " 'datathon': 0.0003729985232227365,\n",
       " 'determin': 0.11344782914572797,\n",
       " 'develop': 0.06732016807573349,\n",
       " 'estrada': 0.2637557394698379,\n",
       " 'few': 0.28169887678795363,\n",
       " 'focus': 0.09071387117190104,\n",
       " 'friend': 0.05304723702105247,\n",
       " 'goal': 0.049260997663310074,\n",
       " 'great': 0.13497516341996343,\n",
       " 'hackathon': 0.09557820293114692,\n",
       " 'hard': 0.11754502433468812,\n",
       " 'have': 0.032385708674737446,\n",
       " 'hei': 0.0050283798806660465,\n",
       " 'here': 0.07372016235676383,\n",
       " 'home': 0.16807355915130623,\n",
       " 'hour': 0.10206922234885396,\n",
       " 'hunger': 0.16477218299606786,\n",
       " 'i': 0.0,\n",
       " 'industri': 0.12453139008722679,\n",
       " 'iot': 0.13186624192495838,\n",
       " 'just': 0.04996433845127072,\n",
       " 'learn': 0.007949443775727157,\n",
       " 'limit': 0.07128392907879441,\n",
       " 'long': 0.11280138068747658,\n",
       " 'm': 0.0,\n",
       " 'make': 0.015054506370476981,\n",
       " 'my': 0.0011662538752823092,\n",
       " 'myself': 0.03620708615613772,\n",
       " 'new': 0.008968970115461364,\n",
       " 'now': 0.20022977049882568,\n",
       " 'object': 0.02191287957044807,\n",
       " 'old': 0.016806611455279914,\n",
       " 'on': 0.09689502688670944,\n",
       " 'particip': 0.046340776487930044,\n",
       " 'particularli': 0.1551796852506111,\n",
       " 'passion': 0.00966234018547587,\n",
       " 'plain': 0.1693014221470784,\n",
       " 'prize': 0.13029718932831844,\n",
       " 'prove': 0.105178143843859,\n",
       " 'push': 0.04297797269873206,\n",
       " 'put': 0.12820521203976024,\n",
       " 'readi': 0.12667792988966345,\n",
       " 'requir': 0.1867315612323537,\n",
       " 'right': 0.16477218299606786,\n",
       " 'rock': 0.16697717976999116,\n",
       " 'simpl': 0.12051089074800546,\n",
       " 'skill': 0.021090163858740872,\n",
       " 'sophia': 0.16477218299606786,\n",
       " 'stai': 0.08633843544927139,\n",
       " 'student': 0.0025393059658321195,\n",
       " 'succe': 0.18010492990021432,\n",
       " 'take': 0.055899522960618814,\n",
       " 'team': 0.2243290191927953,\n",
       " 'tech': 0.03696988459025446,\n",
       " 'three': 0.1383265751294934,\n",
       " 'time': 0.05101838805780818,\n",
       " 'tire': 0.24632560038456258,\n",
       " 'top': 0.14680654920354028,\n",
       " 've': 0.08066927550066519,\n",
       " 'want': 0.03218851561163912,\n",
       " 'what': 0.05041291308546322,\n",
       " 'win': 0.1076723418889691,\n",
       " 'work': 0.05996785031094567,\n",
       " 'year': 0.003393986326928435}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpuses['objective_ind']['Objectives_files/fcee953a-30c6-475a-b65c-ec49223281e9.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from participant import load_participants\n",
    "from rich import print\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "data_path = \"data/datathon_participants.json\"\n",
    "participants = load_participants(data_path)\n",
    "\n",
    "objectives : dict[uuid.UUID,str] = {}\n",
    "\n",
    "technical : dict[uuid.UUID,str] = {}\n",
    "\n",
    "\n",
    "for p in participants:\n",
    "    objectives[p.id] = p.objective + \" \" + p.introduction\n",
    "    technical[p.id] = p.technical_project + \" \" + p.future_excitement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts : dict[str,int] = {}\n",
    "for key, value in objectives.items():\n",
    "    for word in value.split():\n",
    "        if word not in word_counts: \n",
    "            word_counts[word] = 0\n",
    "        word_counts[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m60\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_answer = sorted(word_counts.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "\n",
    "print(word_counts['prize'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">My objective for this datathon is to win, plain and simple. I've been participating in hackathons for a few years \n",
       "now, and I've come close a few times, but I'm tired of just being in the top three. I want to take home that top \n",
       "prize and prove to myself that I have what it takes to be the best. I'm ready to put in the long hours, stay \n",
       "focused, and collaborate with the right team to bring home that win. My goal is clear: I'm not here to make friends\n",
       "or learn new skills, I'm here to win. Hey, I'm Sophia Estrada, an <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>-year-old student with a hunger for coding \n",
       "competitions. I've been participating in hackathons for a few years now, and I'm determined to win this one. I've \n",
       "developed a passion for the tech industry, particularly IoT and blockchain. My goal is to push my skills to the \n",
       "limit and collaborate with a great team to take home the top prize. I'm confident in my abilities, and I'm ready to\n",
       "put in the hard work required to succeed. Bring it on, I'm ready to rock this datathon!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "My objective for this datathon is to win, plain and simple. I've been participating in hackathons for a few years \n",
       "now, and I've come close a few times, but I'm tired of just being in the top three. I want to take home that top \n",
       "prize and prove to myself that I have what it takes to be the best. I'm ready to put in the long hours, stay \n",
       "focused, and collaborate with the right team to bring home that win. My goal is clear: I'm not here to make friends\n",
       "or learn new skills, I'm here to win. Hey, I'm Sophia Estrada, an \u001b[1;36m18\u001b[0m-year-old student with a hunger for coding \n",
       "competitions. I've been participating in hackathons for a few years now, and I'm determined to win this one. I've \n",
       "developed a passion for the tech industry, particularly IoT and blockchain. My goal is to push my skills to the \n",
       "limit and collaborate with a great team to take home the top prize. I'm confident in my abilities, and I'm ready to\n",
       "put in the hard work required to succeed. Bring it on, I'm ready to rock this datathon!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(objectives['fcee953a-30c6-475a-b65c-ec49223281e9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffff00; text-decoration-color: #ffff00\">fcee953a-30c6-475a-b65c-ec49223281e9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[93mfcee953a-30c6-475a-b65c-ec49223281e9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = 'Objectives_files/fcee953a-30c6-475a-b65c-ec49223281e9.txt'\n",
    "resultat = text.split('/')[-1].replace('.txt', '')\n",
    "print(resultat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
